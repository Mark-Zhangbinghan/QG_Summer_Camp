---
typora-root-url: pic for md
---

>python 3.6.13
>
>keras 2.6.0
>
>tensorflow 2.6.2





# 循环神经网络 RNN



# 1.核心

核心：将前方的序列数据用于后方的结果预测

![屏幕截图 2023-10-12 195309](/屏幕截图 2023-10-12 195309.jpg)





# 2.任务

![屏幕截图 2023-10-12 195517](/屏幕截图 2023-10-12 195517.jpg)



- 词汇数值化处理：

  建立一个  **词汇-数值**  一一对应的字典，然后把输入词汇转换为数值矩阵

  对于每一单词编码为 one-hot 独热编码，作为输入

- 字典生成的另一种方式：

  将每个字母作为一个编码，虽然字典更小，但对模型要求更高



# 3. 不同类型的RNN模型

## 3.1 类型

- **基础 RNN**
  - **输入输出维度相同**，多对多
    - 例：上例中识别句子中单词是否为人名

![屏幕截图 2023-10-12 201001](/屏幕截图 2023-10-12 201001.jpg)

- **其他RNN** 
  - **多输入单输出、单输入多输出**

![屏幕截图 2023-10-12 201409](/屏幕截图 2023-10-12 201409.jpg)



- 多输入多输出、维度不一RNN结构

![屏幕截图 2023-10-12 201545](/屏幕截图 2023-10-12 201545.jpg)



## 3.2 普通 RNN 缺陷

- 前部序列信息在传递到后方时，信息的权重下降，重要信息丢失
- 求解过程中梯度消失
- 需要提高前部特定信息的决策权重

![屏幕截图 2023-10-12 202019](/屏幕截图 2023-10-12 202019.jpg)



## 3.3 长短期记忆网络（LSTM）

![屏幕截图 2023-10-12 215717](/屏幕截图 2023-10-12 215717.jpg)

- 简化理解：
  - 相比 a[i]，记忆细胞 c[i] 重点记录前部序列重要信息，且在传递过程中信息丢失少

![屏幕截图 2023-10-12 220120](/屏幕截图 2023-10-12 220120.jpg)



![屏幕截图 2023-10-12 220232](/屏幕截图 2023-10-12 220232.jpg)



## 3.4 双向循环神经网络（BRNN）

- 有时需要用到后部序列信息



## 3.5 深层循环神经网络（DRNN）

- 解决更复杂的序列任务，可以把单层的RNN叠起来或者在输出前和普通mlp结构结合使用



# 4.实战准备

## 4.1 实战1 RNN实现股价预测

- **工作说明：**

![屏幕截图 2023-10-12 221619](/屏幕截图 2023-10-12 221619.jpg)

- **一些准备工作：**
  - 提取序列号数据
    - 使用原数据，slide=8表示使用前八个数据预测后一个数据
    - x 作为分割后的数据，依次利用 x 中的每个样本，预测一个新的股价数据
    - y 作为真实值
  - 普通 RNN 
    - 使用模型序列实例

![屏幕截图 2023-10-12 222252](/屏幕截图 2023-10-12 222252.jpg)



- **输入数据格式**
  - 样本数量可以省略，自动计算
  - 序列长度
  - 样本特征维数

![屏幕截图 2023-10-12 223635](/屏幕截图 2023-10-12 223635.jpg)

## 4.2 实战2 LSTM 自动生成文本

- 任务要求
  - 需要将单词转换为 one-hot 编码

![屏幕截图 2023-10-12 224425](/屏幕截图 2023-10-12 224425.jpg)

- 核心代码：
  - 基本的数据预处理：将 data 中的字符去重，建立数字到字符、字符到数字的映射

![屏幕截图 2023-10-12 225002](/屏幕截图 2023-10-12 225002.jpg)

![屏幕截图 2023-10-12 225502](/屏幕截图 2023-10-12 225502.jpg)

















